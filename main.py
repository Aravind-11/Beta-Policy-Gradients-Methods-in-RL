# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EX2B_QXLyJIwRzOgHTs6w7qOHyeooHx9
"""

import gym
import random
import numpy as np
from collections import deque
import matplotlib.pyplot as plt
from unn import nn_arch,relu,relu_backward,single_layer_forward_propagation,full_forward_propagation,u_full_backward_propagation,single_layer_backward_propagation
from vnn import init_layers
from Adam import initialize_adam
from baseline import b_full_backward_propagation,update_b
from functions import policy, gradients, update_parameters_with_adam

print("Gym:", gym.__version__)

env_name = "Pendulum-v0"
env = gym.make(env_name)
print("Observation space:", env.observation_space)
print("Action space:", env.action_space)

env.observation_space.sample()
env.action_space.sample()

#Hyperparameters
NUM_EPISODES = 1000
learning_rate = 0.001
GAMMA = 0.99

nn_architecture=nn_arch()

u_params_values=init_layers(nn_architecture,seed=99)
v_params_values=init_layers(nn_architecture,seed=99)

state=env.reset()
state=state.reshape(3,1)

a,v,u,c1,c2=policy(state,u_params_values,v_params_values)

u_grads= u_full_backward_propagation(u, a, v,c1, u_params_values, nn_architecture)

state=env.reset()
state=state.reshape(3,1)
#b_params_values=init_layers(nn_architecture,seed=99)
env.reset()
_,reward,_,_ = env.step([2])
#b,c3=full_forward_propagation(state,b_params_values,nn_architecture)
#b_grads=b_full_backward_propagation(b,reward,c3, b_params_values, nn_architecture)

delta_sum={}
for key in u_grads:
    delta_sum[key]=np.zeros((u_grads[key].shape))

''' 
b_params_values=init_layers(nn_architecture,seed=99)
env.reset()
state,reward,
